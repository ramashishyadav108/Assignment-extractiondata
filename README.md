# üìÑ PDF Data Extraction System

A production-ready web application that extracts structured data from PDF documents using LLM technology (OpenAI GPT-4 / Anthropic Claude) and outputs formatted Excel files.

![Python](https://img.shields.io/badge/Python-3.9+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green)
![React](https://img.shields.io/badge/React-18.2-blue)
![License](https://img.shields.io/badge/License-MIT-yellow)

## üéØ Features

- **Multi-file PDF Upload**: Drag & drop interface supporting multiple PDFs
- **Intelligent Extraction**: LLM-powered data extraction with high accuracy
- **Multiple Templates**: Support for different extraction schemas
- **Real-time Progress**: Live extraction status and progress tracking
- **Excel Export**: Professional formatted Excel output
- **Validation**: Multi-layer validation against source documents
- **Error Handling**: Comprehensive error handling and retry logic

## üèóÔ∏è Architecture

```
User ‚Üí React Frontend ‚Üí FastAPI Backend ‚Üí PDF Parser ‚Üí LLM API ‚Üí Excel Generator ‚Üí Download
                              ‚Üì
                        Job Management
```

## üìã Prerequisites

- **Python 3.9+**
- **Node.js 18+**
- **Google Gemini API Key**

## üöÄ Quick Start

### Backend Setup

1. **Navigate to backend directory**:
```bash
cd backend
```

2. **Create virtual environment**:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**:
```bash
pip install -r requirements.txt
```

4. **Configure environment**:
```bash
cp .env.example .env
```

Edit `.env` and add your API keys:
```env
GEMINI_API_KEY=your-gemini-api-key-here
```

5. **Run the server**:
```bash
cd ..
uvicorn backend.app.main:app --reload
```

The API will be available at `http://localhost:8000`

### Frontend Setup

1. **Navigate to frontend directory**:
```bash
cd frontend
```

2. **Install dependencies**:
```bash
npm install
```

3. **Run development server**:
```bash
npm run dev
```

The API will be available at `http://localhost:8000`

---

**Note**: Docker support will be added in future updates.

## üìñ Usage

1. **Open the application** at `http://localhost:5173`
2. **Select extraction template** (Template 1 or Template 2)
3. **Upload PDF files** via drag & drop or file selector
4. **Click "Start Extraction"** to begin processing
5. **Monitor progress** in real-time
6. **Download Excel file** when complete

---

## üîß LLM Configuration

This system uses **Google Gemini** (gemini-1.5-pro) for intelligent data extraction.

### Get Your Gemini API Key

1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Sign in with your Google account
3. Click "Create API Key"
4. Copy the key and add it to `backend/.env`:
   ```env
   GEMINI_API_KEY=your-key-here
   ```

### Supported Models
- `gemini-1.5-pro` (recommended)
- `gemini-1.5-flash` (faster, lower cost)
- `gemini-pro`

Change the model in `.env`:
```env
LLM_MODEL=gemini-1.5-pro
```

## üîß API Documentation

### Endpoints

#### `POST /api/upload`
Upload PDF files for extraction.

**Request**:
- `files`: List of PDF files (multipart/form-data)
- `template_id`: "template_1" or "template_2"

**Response**:
```json
{
  "job_id": "uuid",
  "status": "processing",
  "files_count": 1,
  "message": "Processing 1 file(s)"
}
```

#### `GET /api/status/{job_id}`
Get extraction job status.

**Response**:
```json
{
  "job_id": "uuid",
  "status": "processing",
  "progress": 45.5,
  "files_processed": 1,
  "total_files": 2,
  "errors": [],
  "created_at": "2024-01-01T00:00:00",
  "completed_at": null
}
```

#### `GET /api/download/{job_id}`
Download extracted Excel file.

**Response**: Excel file (.xlsx)

### Interactive API Documentation

Visit `http://localhost:8000/docs` for Swagger UI documentation.

## üìÅ Project Structure

```
pdf-extraction-system/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # API endpoints
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ upload.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ status.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ download.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ extraction.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/         # Core services
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_extractor.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excel_generator.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ template_manager.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ job_manager.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/           # Data models
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/           # Configuration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py           # FastAPI app
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/       # React components
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ FileUpload.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TemplateSelector.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ExtractionProgress.jsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ DownloadButton.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/         # API services
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.css
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.js
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ
‚îú‚îÄ‚îÄ templates/                # Extraction templates
‚îÇ   ‚îú‚îÄ‚îÄ template_1.json
‚îÇ   ‚îî‚îÄ‚îÄ template_2.json
‚îÇ
‚îú‚îÄ‚îÄ tests/                    # Test files
‚îÇ   ‚îú‚îÄ‚îÄ test_extraction.py
‚îÇ   ‚îî‚îÄ‚îÄ test_accuracy.py
‚îÇ
‚îú‚îÄ‚îÄ examples/                 # Sample files
‚îÇ   ‚îú‚îÄ‚îÄ sample_pdfs/
‚îÇ   ‚îî‚îÄ‚îÄ output/
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

## üé® Templates

### Template 1 - Comprehensive Fund Data
Extracts detailed fund information including:
- Fund details (name, manager, vintage, size)
- Investment metrics (IRR, TVPI, DPI, RVPI)
- Capital information (commitments, distributions)
- Portfolio composition
- Fee structure

### Template 2 - Key Metrics
Extracts essential metrics:
- Fund identification
- Financial values (NAV, distributions)
- Performance multiples
- Key dates

## üß™ Testing

### Run Backend Tests
```bash
cd backend
pytest tests/
```

### Run Accuracy Tests
```bash
pytest tests/test_accuracy.py -v
```

### Manual Testing
1. Place test PDFs in `examples/sample_pdfs/`
2. Run extraction
3. Compare output with expected files in `examples/output/`

## üîí Security Best Practices

- ‚úÖ API keys stored in environment variables
- ‚úÖ File type validation
- ‚úÖ File size limits (50MB)
- ‚úÖ CORS configuration
- ‚úÖ Input sanitization
- ‚úÖ Error message sanitization

## ‚öôÔ∏è Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GEMINI_API_KEY` | Google Gemini API key | Required |
| `LLM_MODEL` | Model to use | gemini-1.5-pro |
| `LLM_TEMPERATURE` | Model temperature | 0.1 |
| `MAX_UPLOAD_SIZE` | Max file size (bytes) | 52428800 |
| `CORS_ORIGINS` | Allowed origins | ["http://localhost:3000", "http://localhost:5173"] |

### Supported LLM Models

- Google Gemini: `gemini-1.5-pro`, `gemini-1.5-flash`, `gemini-pro`

## üìä Performance

- **Extraction Accuracy**: >95% on test documents
- **Processing Time**: ~30-60 seconds per document
- **Concurrent Jobs**: Supports multiple simultaneous extractions
- **File Support**: PDF files up to 50MB

## üöÄ Deployment

### Production Deployment Checklist

- [ ] Set `DEBUG=False` in environment
- [ ] Configure production database (PostgreSQL)
- [ ] Set up proper CORS origins
- [ ] Enable HTTPS
- [ ] Configure rate limiting
- [ ] Set up logging and monitoring
- [ ] Configure file cleanup jobs
- [ ] Set up backup strategy
- [ ] Enable API authentication (if needed)

### Deploy to Cloud

#### Vercel (Frontend)
```bash
cd frontend
npm run build
# Deploy dist/ folder to Vercel
```

#### Railway/Render (Backend)
```bash
# Use Dockerfile for deployment
# Set environment variables in platform
```

#### AWS/GCP/Azure
Use provided Dockerfile and docker-compose.yml for containerized deployment.

## üêõ Troubleshooting

### Common Issues

**Issue**: "Import errors" when running backend
```bash
# Ensure you're in the correct directory and virtual environment is activated
cd pdf-extraction-system
source backend/venv/bin/activate
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

**Issue**: "API key not configured"
```bash
# Check .env file exists and contains valid keys
cat backend/.env
```

**Issue**: "CORS errors" in frontend
```bash
# Update CORS_ORIGINS in .env to include your frontend URL
CORS_ORIGINS=["http://localhost:5173", "https://your-domain.com"]
```

**Issue**: "Extraction accuracy low"
- Ensure PDF text is extractable (not scanned images)
- Try adjusting LLM_TEMPERATURE
- Customize extraction prompt for specific document types
- Consider using OCR for scanned documents

---

## üöÄ Deployment

### Single-Push Deployment (Recommended)

Deploy both frontend and backend in **ONE PUSH**! See **[DEPLOY.md](./DEPLOY.md)** for complete guide.

#### Option 1: All on Render (Simplest)
```bash
git push origin main
# Both frontend + backend deploy automatically via render.yaml!
```

- ‚úÖ Single platform
- ‚úÖ Auto-configured CORS  
- ‚úÖ Free tier available
- üåê URLs: 
  - Backend: `https://pdf-extraction-backend.onrender.com`
  - Frontend: `https://pdf-extraction-frontend.onrender.com`

#### Option 2: Render + Vercel
- Backend on Render (Python web service)
- Frontend on Vercel (Static CDN)
- Better for high-traffic applications

**Quick Steps:**
1. Push to GitHub: `git push origin main`
2. Connect to Render/Vercel dashboard
3. Add `GEMINI_API_KEY` environment variable
4. Done! üéâ

**Detailed Instructions:** See [DEPLOY.md](./DEPLOY.md)

### Environment Variables for Production

**Backend (Render):**
```env
GEMINI_API_KEY=your_actual_api_key
PYTHON_VERSION=3.11.0
LLM_MODEL=gemini-2.5-flash
DEBUG=False
CORS_ORIGINS=["https://your-frontend-url.com"]
```

**Frontend (Vercel/Render):**
```env
VITE_API_URL=https://your-backend-url.com/api
```

### Pre-Deployment Checklist
- [ ] `.env` files not in git (check `.gitignore`)
- [ ] API keys secured in platform environment variables
- [ ] CORS configured with production URLs
- [ ] Frontend built successfully (`npm run build`)
- [ ] Backend tested locally

See **[PRE_DEPLOYMENT_CHECKLIST.md](./PRE_DEPLOYMENT_CHECKLIST.md)** for complete list.

---

## ü§ù Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## üìù License

This project is licensed under the MIT License.

## üôè Acknowledgments

- FastAPI for the excellent web framework
- OpenAI/Anthropic for LLM APIs
- pdfplumber for PDF parsing
- openpyxl for Excel generation

## üìû Support

For issues and questions:
- Create an issue on GitHub
- Check existing documentation
- Review API documentation at `/docs`

## üîÑ Version History

### v1.0.0 (2024-01-01)
- Initial release
- Support for GPT-4 and Claude 3.5
- Two extraction templates
- React frontend with real-time progress
- Docker support

---

**Built with ‚ù§Ô∏è Joy  using React, FastAPI, and LLM Technology**
